

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>azure.cognitiveservices.vision.computervision.operations module &mdash; Azure SDK for Python 2.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="azure.cognitiveservices.vision.contentmoderator package" href="azure.cognitiveservices.vision.contentmoderator.html" />
    <link rel="prev" title="azure.cognitiveservices.vision.computervision.models module" href="azure.cognitiveservices.vision.computervision.models.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Azure SDK for Python
          

          
          </a>

          
            
            
              <div class="version">
                2.0.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart_authentication.html">Resource Management Authentication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../multicloud.html">Multi-cloud - use Azure on all regions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exceptions.html">Exception handling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../servicemanagement.html">Service Management (Legacy)</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="azure.common.html">azure.common package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.applicationinsights.html">azure.applicationinsights package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.batch.html">azure.batch package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.anomalydetector.html">azure.cognitiveservices.anomalydetector package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.knowledge.qnamaker.html">azure.cognitiveservices.knowledge.qnamaker package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.language.luis.authoring.html">azure.cognitiveservices.language.luis.authoring package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.language.luis.runtime.html">azure.cognitiveservices.language.luis.runtime package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.language.spellcheck.html">azure.cognitiveservices.language.spellcheck package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.language.textanalytics.html">azure.cognitiveservices.language.textanalytics package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.search.autosuggest.html">azure.cognitiveservices.search.autosuggest package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.search.customimagesearch.html">azure.cognitiveservices.search.customimagesearch package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.search.customsearch.html">azure.cognitiveservices.search.customsearch package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.search.entitysearch.html">azure.cognitiveservices.search.entitysearch package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.search.imagesearch.html">azure.cognitiveservices.search.imagesearch package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.search.newssearch.html">azure.cognitiveservices.search.newssearch package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.search.videosearch.html">azure.cognitiveservices.search.videosearch package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.search.visualsearch.html">azure.cognitiveservices.search.visualsearch package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.search.websearch.html">azure.cognitiveservices.search.websearch package</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="azure.cognitiveservices.vision.computervision.html">azure.cognitiveservices.vision.computervision package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="azure.cognitiveservices.vision.computervision.html#submodules">Submodules</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html">azure.cognitiveservices.vision.computervision.models module</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">azure.cognitiveservices.vision.computervision.operations module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="azure.cognitiveservices.vision.computervision.html#module-azure.cognitiveservices.vision.computervision">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.vision.contentmoderator.html">azure.cognitiveservices.vision.contentmoderator package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.vision.customvision.prediction.html">azure.cognitiveservices.vision.customvision.prediction package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.vision.customvision.training.html">azure.cognitiveservices.vision.customvision.training package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cognitiveservices.vision.face.html">azure.cognitiveservices.vision.face package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.core.html">azure.core package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.cosmos.html">azure.cosmos package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.eventgrid.html">azure.eventgrid package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.eventhub.html">azure.eventhub package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.eventhub.extensions.html">azure.eventhub.extensions package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.graphrbac.html">azure.graphrbac package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.identity.html">azure.identity package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.keyvault.keys.html">azure.keyvault.keys package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.keyvault.secrets.html">azure.keyvault.secrets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.loganalytics.html">azure.loganalytics package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.advisor.html">azure.mgmt.advisor package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.alertsmanagement.html">azure.mgmt.alertsmanagement package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.apimanagement.html">azure.mgmt.apimanagement package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.applicationinsights.html">azure.mgmt.applicationinsights package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.authorization.html">azure.mgmt.authorization package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.automation.html">azure.mgmt.automation package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.batch.html">azure.mgmt.batch package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.batchai.html">azure.mgmt.batchai package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.billing.html">azure.mgmt.billing package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.cdn.html">azure.mgmt.cdn package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.cognitiveservices.html">azure.mgmt.cognitiveservices package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.commerce.html">azure.mgmt.commerce package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.compute.html">azure.mgmt.compute package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.consumption.html">azure.mgmt.consumption package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.containerinstance.html">azure.mgmt.containerinstance package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.containerregistry.html">azure.mgmt.containerregistry package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.containerservice.html">azure.mgmt.containerservice package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.cosmosdb.html">azure.mgmt.cosmosdb package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.databricks.html">azure.mgmt.databricks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.datafactory.html">azure.mgmt.datafactory package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.datalake.analytics.account.html">azure.mgmt.datalake.analytics.account package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.datalake.analytics.catalog.html">azure.mgmt.datalake.analytics.catalog package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.datalake.analytics.job.html">azure.mgmt.datalake.analytics.job package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.datalake.store.html">azure.mgmt.datalake.store package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.datamigration.html">azure.mgmt.datamigration package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.devspaces.html">azure.mgmt.devspaces package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.devtestlabs.html">azure.mgmt.devtestlabs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.dns.html">azure.mgmt.dns package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.eventgrid.html">azure.mgmt.eventgrid package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.eventhub.html">azure.mgmt.eventhub package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.hanaonazure.html">azure.mgmt.hanaonazure package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.hdinsight.html">azure.mgmt.hdinsight package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.imagebuilder.html">azure.mgmt.imagebuilder package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.iotcentral.html">azure.mgmt.iotcentral package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.iothub.html">azure.mgmt.iothub package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.iothubprovisioningservices.html">azure.mgmt.iothubprovisioningservices package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.keyvault.html">azure.mgmt.keyvault package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.kusto.html">azure.mgmt.kusto package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.labservices.html">azure.mgmt.labservices package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.loganalytics.html">azure.mgmt.loganalytics package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.logic.html">azure.mgmt.logic package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.machinelearningcompute.html">azure.mgmt.machinelearningcompute package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.managementgroups.html">azure.mgmt.managementgroups package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.managementpartner.html">azure.mgmt.managementpartner package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.maps.html">azure.mgmt.maps package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.marketplaceordering.html">azure.mgmt.marketplaceordering package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.media.html">azure.mgmt.media package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.mixedreality.html">azure.mgmt.mixedreality package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.monitor.html">azure.mgmt.monitor package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.msi.html">azure.mgmt.msi package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.netapp.html">azure.mgmt.netapp package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.network.html">azure.mgmt.network package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.notificationhubs.html">azure.mgmt.notificationhubs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.policyinsights.html">azure.mgmt.policyinsights package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.powerbiembedded.html">azure.mgmt.powerbiembedded package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.rdbms.mariadb.html">azure.mgmt.rdbms.mariadb package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.rdbms.mysql.html">azure.mgmt.rdbms.mysql package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.rdbms.postgresql.html">azure.mgmt.rdbms.postgresql package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.recoveryservices.html">azure.mgmt.recoveryservices package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.recoveryservicesbackup.html">azure.mgmt.recoveryservicesbackup package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.redis.html">azure.mgmt.redis package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.relay.html">azure.mgmt.relay package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.resource.features.html">azure.mgmt.resource.features package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.resource.links.html">azure.mgmt.resource.links package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.resource.locks.html">azure.mgmt.resource.locks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.resource.managedapplications.html">azure.mgmt.resource.managedapplications package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.resource.policy.html">azure.mgmt.resource.policy package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.resource.resources.html">azure.mgmt.resource.resources package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.resource.subscriptions.html">azure.mgmt.resource.subscriptions package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.resourcegraph.html">azure.mgmt.resourcegraph package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.scheduler.html">azure.mgmt.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.search.html">azure.mgmt.search package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.security.html">azure.mgmt.security package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.servermanager.html">azure.mgmt.servermanager package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.servicebus.html">azure.mgmt.servicebus package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.servicefabric.html">azure.mgmt.servicefabric package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.signalr.html">azure.mgmt.signalr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.sql.html">azure.mgmt.sql package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.sqlvirtualmachine.html">azure.mgmt.sqlvirtualmachine package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.storage.html">azure.mgmt.storage package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.subscription.html">azure.mgmt.subscription package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.trafficmanager.html">azure.mgmt.trafficmanager package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.mgmt.web.html">azure.mgmt.web package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.servicebus.html">azure.servicebus package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.servicefabric.html">azure.servicefabric package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.storage.blob.html">azure.storage.blob package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.storage.file.html">azure.storage.file package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.storage.queue.html">azure.storage.queue package</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure.servicemanagement.html">azure.servicemanagement package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Azure SDK for Python</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="azure.cognitiveservices.vision.computervision.html">azure.cognitiveservices.vision.computervision package</a> &raquo;</li>
        
      <li>azure.cognitiveservices.vision.computervision.operations module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/ref/azure.cognitiveservices.vision.computervision.operations.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-azure.cognitiveservices.vision.computervision.operations">
<span id="azure-cognitiveservices-vision-computervision-operations-module"></span><h1>azure.cognitiveservices.vision.computervision.operations module<a class="headerlink" href="#module-azure.cognitiveservices.vision.computervision.operations" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin">
<em class="property">class </em><code class="sig-prename descclassname">azure.cognitiveservices.vision.computervision.operations.</code><code class="sig-name descname">ComputerVisionClientOperationsMixin</code><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.5/library/functions.html#object" title="(in Python v3.5)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image">
<code class="sig-name descname">analyze_image</code><span class="sig-paren">(</span><em class="sig-param">url</em>, <em class="sig-param">visual_features=None</em>, <em class="sig-param">details=None</em>, <em class="sig-param">language='en'</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.analyze_image"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation extracts a rich set of visual features based on the
image content.
Two input methods are supported – (1) Uploading an image or (2)
specifying an image URL. Within your request, there is an optional
parameter to allow you to choose which features to return. By default,
image categories are returned in the response.
A successful response will be returned in JSON. If the request failed,
the response will contain an error code and a message to help
understand what went wrong.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>url</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – Publicly reachable URL of an image.</p></li>
<li><p><strong>visual_features</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#list" title="(in Python v3.5)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a><em> or
</em><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.VisualFeatureTypes" title="azure.cognitiveservices.vision.computervision.models.VisualFeatureTypes"><em>VisualFeatureTypes</em></a><em>]</em>) – A string indicating what visual feature types
to return. Multiple values should be comma-separated. Valid visual
feature types include: Categories - categorizes image content
according to a taxonomy defined in documentation. Tags - tags the
image with a detailed list of words related to the image content.
Description - describes the image content with a complete English
sentence. Faces - detects if faces are present. If present, generate
coordinates, gender and age. ImageType - detects if image is clipart
or a line drawing. Color - determines the accent color, dominant
color, and whether an image is black&amp;white. Adult - detects if the
image is pornographic in nature (depicts nudity or a sex act).
Sexually suggestive content is also detected. Objects - detects
various objects within an image, including the approximate location.
The Objects argument is only available in English. Brands - detects
various brands within an image, including the approximate location.
The Brands argument is only available in English.</p></li>
<li><p><strong>details</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#list" title="(in Python v3.5)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a><em> or
</em><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.Details" title="azure.cognitiveservices.vision.computervision.models.Details"><em>Details</em></a><em>]</em>) – A string indicating which domain-specific details to
return. Multiple values should be comma-separated. Valid visual
feature types include: Celebrities - identifies celebrities if
detected in the image, Landmarks - identifies notable landmarks in the
image.</p></li>
<li><p><strong>language</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – The desired language for output generation. If this
parameter is not specified, the default value is
&amp;quot;en&amp;quot;.Supported languages:en - English, Default. es -
Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.
Possible values include: ‘en’, ‘es’, ‘ja’, ‘pt’, ‘zh’</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ImageAnalysis or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ImageAnalysis" title="azure.cognitiveservices.vision.computervision.models.ImageAnalysis">ImageAnalysis</a> or
ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain">
<code class="sig-name descname">analyze_image_by_domain</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">url</em>, <em class="sig-param">language='en'</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.analyze_image_by_domain"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation recognizes content within an image by applying a
domain-specific model. The list of domain-specific models that are
supported by the Computer Vision API can be retrieved using the /models
GET request. Currently, the API provides following domain-specific
models: celebrities, landmarks.
Two input methods are supported – (1) Uploading an image or (2)
specifying an image URL.
A successful response will be returned in JSON.
If the request failed, the response will contain an error code and a
message to help understand what went wrong.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – The domain-specific content to recognize.</p></li>
<li><p><strong>url</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – Publicly reachable URL of an image.</p></li>
<li><p><strong>language</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – The desired language for output generation. If this
parameter is not specified, the default value is
&amp;quot;en&amp;quot;.Supported languages:en - English, Default. es -
Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.
Possible values include: ‘en’, ‘es’, ‘ja’, ‘pt’, ‘zh’</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>DomainModelResults or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.DomainModelResults" title="azure.cognitiveservices.vision.computervision.models.DomainModelResults">DomainModelResults</a>
or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain_in_stream">
<code class="sig-name descname">analyze_image_by_domain_in_stream</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">image</em>, <em class="sig-param">language='en'</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.analyze_image_by_domain_in_stream"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain_in_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation recognizes content within an image by applying a
domain-specific model. The list of domain-specific models that are
supported by the Computer Vision API can be retrieved using the /models
GET request. Currently, the API provides following domain-specific
models: celebrities, landmarks.
Two input methods are supported – (1) Uploading an image or (2)
specifying an image URL.
A successful response will be returned in JSON.
If the request failed, the response will contain an error code and a
message to help understand what went wrong.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – The domain-specific content to recognize.</p></li>
<li><p><strong>image</strong> (<em>Generator</em>) – An image stream.</p></li>
<li><p><strong>language</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – The desired language for output generation. If this
parameter is not specified, the default value is
&amp;quot;en&amp;quot;.Supported languages:en - English, Default. es -
Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.
Possible values include: ‘en’, ‘es’, ‘ja’, ‘pt’, ‘zh’</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>Bytes</em><em>, </em><em>response=None</em><em>]</em>) – When specified, will be called with each chunk of
data that is streamed. The callback should take two arguments, the
bytes of the current chunk of data and the response object. If the
data is uploading, response will be None.</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>DomainModelResults or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.DomainModelResults" title="azure.cognitiveservices.vision.computervision.models.DomainModelResults">DomainModelResults</a>
or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_in_stream">
<code class="sig-name descname">analyze_image_in_stream</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">visual_features=None</em>, <em class="sig-param">details=None</em>, <em class="sig-param">language='en'</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.analyze_image_in_stream"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_in_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation extracts a rich set of visual features based on the
image content.
Two input methods are supported – (1) Uploading an image or (2)
specifying an image URL. Within your request, there is an optional
parameter to allow you to choose which features to return. By default,
image categories are returned in the response.
A successful response will be returned in JSON. If the request failed,
the response will contain an error code and a message to help
understand what went wrong.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>Generator</em>) – An image stream.</p></li>
<li><p><strong>visual_features</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#list" title="(in Python v3.5)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a><em> or
</em><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.VisualFeatureTypes" title="azure.cognitiveservices.vision.computervision.models.VisualFeatureTypes"><em>VisualFeatureTypes</em></a><em>]</em>) – A string indicating what visual feature types
to return. Multiple values should be comma-separated. Valid visual
feature types include: Categories - categorizes image content
according to a taxonomy defined in documentation. Tags - tags the
image with a detailed list of words related to the image content.
Description - describes the image content with a complete English
sentence. Faces - detects if faces are present. If present, generate
coordinates, gender and age. ImageType - detects if image is clipart
or a line drawing. Color - determines the accent color, dominant
color, and whether an image is black&amp;white. Adult - detects if the
image is pornographic in nature (depicts nudity or a sex act).
Sexually suggestive content is also detected. Objects - detects
various objects within an image, including the approximate location.
The Objects argument is only available in English. Brands - detects
various brands within an image, including the approximate location.
The Brands argument is only available in English.</p></li>
<li><p><strong>details</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#list" title="(in Python v3.5)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a><em> or
</em><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.Details" title="azure.cognitiveservices.vision.computervision.models.Details"><em>Details</em></a><em>]</em>) – A string indicating which domain-specific details to
return. Multiple values should be comma-separated. Valid visual
feature types include: Celebrities - identifies celebrities if
detected in the image, Landmarks - identifies notable landmarks in the
image.</p></li>
<li><p><strong>language</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – The desired language for output generation. If this
parameter is not specified, the default value is
&amp;quot;en&amp;quot;.Supported languages:en - English, Default. es -
Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.
Possible values include: ‘en’, ‘es’, ‘ja’, ‘pt’, ‘zh’</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>Bytes</em><em>, </em><em>response=None</em><em>]</em>) – When specified, will be called with each chunk of
data that is streamed. The callback should take two arguments, the
bytes of the current chunk of data and the response object. If the
data is uploading, response will be None.</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ImageAnalysis or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ImageAnalysis" title="azure.cognitiveservices.vision.computervision.models.ImageAnalysis">ImageAnalysis</a> or
ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.batch_read_file">
<code class="sig-name descname">batch_read_file</code><span class="sig-paren">(</span><em class="sig-param">url</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.batch_read_file"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.batch_read_file" title="Permalink to this definition">¶</a></dt>
<dd><p>Use this interface to get the result of a Read operation, employing the
state-of-the-art Optical Character Recognition (OCR) algorithms
optimized for text-heavy documents. When you use the Read File
interface, the response contains a field called ‘Operation-Location’.
The ‘Operation-Location’ field contains the URL that you must use for
your ‘GetReadOperationResult’ operation to access OCR results.​.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>url</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – Publicly reachable URL of an image.</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.5/library/constants.html#None" title="(in Python v3.5)">None</a> or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.batch_read_file_in_stream">
<code class="sig-name descname">batch_read_file_in_stream</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.batch_read_file_in_stream"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.batch_read_file_in_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>Use this interface to get the result of a Read Document operation,
employing the state-of-the-art Optical Character Recognition (OCR)
algorithms optimized for text-heavy documents. When you use the Read
Document interface, the response contains a field called
‘Operation-Location’. The ‘Operation-Location’ field contains the URL
that you must use for your ‘Get Read Result operation’ to access OCR
results.​.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>Generator</em>) – An image stream.</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>Bytes</em><em>, </em><em>response=None</em><em>]</em>) – When specified, will be called with each chunk of
data that is streamed. The callback should take two arguments, the
bytes of the current chunk of data and the response object. If the
data is uploading, response will be None.</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.5/library/constants.html#None" title="(in Python v3.5)">None</a> or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image">
<code class="sig-name descname">describe_image</code><span class="sig-paren">(</span><em class="sig-param">url</em>, <em class="sig-param">max_candidates=1</em>, <em class="sig-param">language='en'</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.describe_image"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation generates a description of an image in human readable
language with complete sentences. The description is based on a
collection of content tags, which are also returned by the operation.
More than one description can be generated for each image. Descriptions
are ordered by their confidence score. All descriptions are in English.
Two input methods are supported – (1) Uploading an image or (2)
specifying an image URL.
A successful response will be returned in JSON. If the request failed,
the response will contain an error code and a message to help
understand what went wrong.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>url</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – Publicly reachable URL of an image.</p></li>
<li><p><strong>max_candidates</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#int" title="(in Python v3.5)"><em>int</em></a>) – Maximum number of candidate descriptions to be
returned.  The default is 1.</p></li>
<li><p><strong>language</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – The desired language for output generation. If this
parameter is not specified, the default value is
&amp;quot;en&amp;quot;.Supported languages:en - English, Default. es -
Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.
Possible values include: ‘en’, ‘es’, ‘ja’, ‘pt’, ‘zh’</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ImageDescription or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ImageDescription" title="azure.cognitiveservices.vision.computervision.models.ImageDescription">ImageDescription</a>
or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image_in_stream">
<code class="sig-name descname">describe_image_in_stream</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">max_candidates=1</em>, <em class="sig-param">language='en'</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.describe_image_in_stream"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image_in_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation generates a description of an image in human readable
language with complete sentences. The description is based on a
collection of content tags, which are also returned by the operation.
More than one description can be generated for each image. Descriptions
are ordered by their confidence score. All descriptions are in English.
Two input methods are supported – (1) Uploading an image or (2)
specifying an image URL.
A successful response will be returned in JSON. If the request failed,
the response will contain an error code and a message to help
understand what went wrong.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>Generator</em>) – An image stream.</p></li>
<li><p><strong>max_candidates</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#int" title="(in Python v3.5)"><em>int</em></a>) – Maximum number of candidate descriptions to be
returned.  The default is 1.</p></li>
<li><p><strong>language</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – The desired language for output generation. If this
parameter is not specified, the default value is
&amp;quot;en&amp;quot;.Supported languages:en - English, Default. es -
Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.
Possible values include: ‘en’, ‘es’, ‘ja’, ‘pt’, ‘zh’</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>Bytes</em><em>, </em><em>response=None</em><em>]</em>) – When specified, will be called with each chunk of
data that is streamed. The callback should take two arguments, the
bytes of the current chunk of data and the response object. If the
data is uploading, response will be None.</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ImageDescription or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ImageDescription" title="azure.cognitiveservices.vision.computervision.models.ImageDescription">ImageDescription</a>
or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects">
<code class="sig-name descname">detect_objects</code><span class="sig-paren">(</span><em class="sig-param">url</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.detect_objects"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs object detection on the specified image.
Two input methods are supported – (1) Uploading an image or (2)
specifying an image URL.
A successful response will be returned in JSON. If the request failed,
the response will contain an error code and a message to help
understand what went wrong.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>url</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – Publicly reachable URL of an image.</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>DetectResult or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.DetectResult" title="azure.cognitiveservices.vision.computervision.models.DetectResult">DetectResult</a> or
ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects_in_stream">
<code class="sig-name descname">detect_objects_in_stream</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.detect_objects_in_stream"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects_in_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs object detection on the specified image.
Two input methods are supported – (1) Uploading an image or (2)
specifying an image URL.
A successful response will be returned in JSON. If the request failed,
the response will contain an error code and a message to help
understand what went wrong.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>Generator</em>) – An image stream.</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>Bytes</em><em>, </em><em>response=None</em><em>]</em>) – When specified, will be called with each chunk of
data that is streamed. The callback should take two arguments, the
bytes of the current chunk of data and the response object. If the
data is uploading, response will be None.</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>DetectResult or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.DetectResult" title="azure.cognitiveservices.vision.computervision.models.DetectResult">DetectResult</a> or
ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail">
<code class="sig-name descname">generate_thumbnail</code><span class="sig-paren">(</span><em class="sig-param">width</em>, <em class="sig-param">height</em>, <em class="sig-param">url</em>, <em class="sig-param">smart_cropping=False</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.generate_thumbnail"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation generates a thumbnail image with the user-specified
width and height. By default, the service analyzes the image,
identifies the region of interest (ROI), and generates smart cropping
coordinates based on the ROI. Smart cropping helps when you specify an
aspect ratio that differs from that of the input image.
A successful response contains the thumbnail image binary. If the
request failed, the response contains an error code and a message to
help determine what went wrong.
Upon failure, the error code and an error message are returned. The
error code could be one of InvalidImageUrl, InvalidImageFormat,
InvalidImageSize, InvalidThumbnailSize, NotSupportedImage,
FailedToProcess, Timeout, or InternalServerError.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>width</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#int" title="(in Python v3.5)"><em>int</em></a>) – Width of the thumbnail, in pixels. It must be between 1
and 1024. Recommended minimum of 50.</p></li>
<li><p><strong>height</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#int" title="(in Python v3.5)"><em>int</em></a>) – Height of the thumbnail, in pixels. It must be between
1 and 1024. Recommended minimum of 50.</p></li>
<li><p><strong>url</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – Publicly reachable URL of an image.</p></li>
<li><p><strong>smart_cropping</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – Boolean flag for enabling smart cropping.</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>Bytes</em><em>, </em><em>response=None</em><em>]</em>) – When specified, will be called with each chunk of
data that is streamed. The callback should take two arguments, the
bytes of the current chunk of data and the response object. If the
data is uploading, response will be None.</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>object or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Generator or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">HttpOperationError</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail_in_stream">
<code class="sig-name descname">generate_thumbnail_in_stream</code><span class="sig-paren">(</span><em class="sig-param">width</em>, <em class="sig-param">height</em>, <em class="sig-param">image</em>, <em class="sig-param">smart_cropping=False</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.generate_thumbnail_in_stream"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail_in_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation generates a thumbnail image with the user-specified
width and height. By default, the service analyzes the image,
identifies the region of interest (ROI), and generates smart cropping
coordinates based on the ROI. Smart cropping helps when you specify an
aspect ratio that differs from that of the input image.
A successful response contains the thumbnail image binary. If the
request failed, the response contains an error code and a message to
help determine what went wrong.
Upon failure, the error code and an error message are returned. The
error code could be one of InvalidImageUrl, InvalidImageFormat,
InvalidImageSize, InvalidThumbnailSize, NotSupportedImage,
FailedToProcess, Timeout, or InternalServerError.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>width</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#int" title="(in Python v3.5)"><em>int</em></a>) – Width of the thumbnail, in pixels. It must be between 1
and 1024. Recommended minimum of 50.</p></li>
<li><p><strong>height</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#int" title="(in Python v3.5)"><em>int</em></a>) – Height of the thumbnail, in pixels. It must be between
1 and 1024. Recommended minimum of 50.</p></li>
<li><p><strong>image</strong> (<em>Generator</em>) – An image stream.</p></li>
<li><p><strong>smart_cropping</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – Boolean flag for enabling smart cropping.</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>Bytes</em><em>, </em><em>response=None</em><em>]</em>) – When specified, will be called with each chunk of
data that is streamed. The callback should take two arguments, the
bytes of the current chunk of data and the response object. If the
data is uploading, response will be None.</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>object or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Generator or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">HttpOperationError</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest">
<code class="sig-name descname">get_area_of_interest</code><span class="sig-paren">(</span><em class="sig-param">url</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.get_area_of_interest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation returns a bounding box around the most important area of
the image.
A successful response will be returned in JSON. If the request failed,
the response contains an error code and a message to help determine
what went wrong.
Upon failure, the error code and an error message are returned. The
error code could be one of InvalidImageUrl, InvalidImageFormat,
InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or
InternalServerError.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>url</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – Publicly reachable URL of an image.</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>AreaOfInterestResult or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.AreaOfInterestResult" title="azure.cognitiveservices.vision.computervision.models.AreaOfInterestResult">AreaOfInterestResult</a>
or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest_in_stream">
<code class="sig-name descname">get_area_of_interest_in_stream</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.get_area_of_interest_in_stream"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest_in_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation returns a bounding box around the most important area of
the image.
A successful response will be returned in JSON. If the request failed,
the response contains an error code and a message to help determine
what went wrong.
Upon failure, the error code and an error message are returned. The
error code could be one of InvalidImageUrl, InvalidImageFormat,
InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or
InternalServerError.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>Generator</em>) – An image stream.</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>Bytes</em><em>, </em><em>response=None</em><em>]</em>) – When specified, will be called with each chunk of
data that is streamed. The callback should take two arguments, the
bytes of the current chunk of data and the response object. If the
data is uploading, response will be None.</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>AreaOfInterestResult or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.AreaOfInterestResult" title="azure.cognitiveservices.vision.computervision.models.AreaOfInterestResult">AreaOfInterestResult</a>
or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_read_operation_result">
<code class="sig-name descname">get_read_operation_result</code><span class="sig-paren">(</span><em class="sig-param">operation_id</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.get_read_operation_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_read_operation_result" title="Permalink to this definition">¶</a></dt>
<dd><p>This interface is used for getting OCR results of Read operation. The
URL to this interface should be retrieved from ‘Operation-Location’
field returned from Batch Read File interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>operation_id</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – Id of read operation returned in the response of
the ‘Batch Read File’ interface.</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ReadOperationResult or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ReadOperationResult" title="azure.cognitiveservices.vision.computervision.models.ReadOperationResult">ReadOperationResult</a>
or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_text_operation_result">
<code class="sig-name descname">get_text_operation_result</code><span class="sig-paren">(</span><em class="sig-param">operation_id</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.get_text_operation_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_text_operation_result" title="Permalink to this definition">¶</a></dt>
<dd><p>This interface is used for getting text operation result. The URL to
this interface should be retrieved from ‘Operation-Location’ field
returned from Recognize Text interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>operation_id</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – Id of the text operation returned in the response
of the ‘Recognize Text’</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>TextOperationResult or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.TextOperationResult" title="azure.cognitiveservices.vision.computervision.models.TextOperationResult">TextOperationResult</a>
or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.list_models">
<code class="sig-name descname">list_models</code><span class="sig-paren">(</span><em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.list_models"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.list_models" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation returns the list of domain-specific models that are
supported by the Computer Vision API. Currently, the API supports
following domain-specific models: celebrity recognizer, landmark
recognizer.
A successful response will be returned in JSON. If the request failed,
the response will contain an error code and a message to help
understand what went wrong.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ListModelsResult or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ListModelsResult" title="azure.cognitiveservices.vision.computervision.models.ListModelsResult">ListModelsResult</a>
or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text">
<code class="sig-name descname">recognize_printed_text</code><span class="sig-paren">(</span><em class="sig-param">url</em>, <em class="sig-param">detect_orientation=True</em>, <em class="sig-param">language='unk'</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.recognize_printed_text"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text" title="Permalink to this definition">¶</a></dt>
<dd><p>Optical Character Recognition (OCR) detects text in an image and
extracts the recognized characters into a machine-usable character
stream.
Upon success, the OCR results will be returned.
Upon failure, the error code together with an error message will be
returned. The error code can be one of InvalidImageUrl,
InvalidImageFormat, InvalidImageSize, NotSupportedImage,
NotSupportedLanguage, or InternalServerError.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>detect_orientation</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – Whether detect the text orientation in the
image. With detectOrientation=true the OCR service tries to detect the
image orientation and correct it before further processing (e.g. if
it’s upside-down).</p></li>
<li><p><strong>url</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – Publicly reachable URL of an image.</p></li>
<li><p><strong>language</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a><em> or
</em><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.OcrLanguages" title="azure.cognitiveservices.vision.computervision.models.OcrLanguages"><em>OcrLanguages</em></a>) – The BCP-47 language code of the text to be detected
in the image. The default value is ‘unk’. Possible values include:
‘unk’, ‘zh-Hans’, ‘zh-Hant’, ‘cs’, ‘da’, ‘nl’, ‘en’, ‘fi’, ‘fr’, ‘de’,
‘el’, ‘hu’, ‘it’, ‘ja’, ‘ko’, ‘nb’, ‘pl’, ‘pt’, ‘ru’, ‘es’, ‘sv’,
‘tr’, ‘ar’, ‘ro’, ‘sr-Cyrl’, ‘sr-Latn’, ‘sk’</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>OcrResult or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.OcrResult" title="azure.cognitiveservices.vision.computervision.models.OcrResult">OcrResult</a> or
ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text_in_stream">
<code class="sig-name descname">recognize_printed_text_in_stream</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">detect_orientation=True</em>, <em class="sig-param">language='unk'</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.recognize_printed_text_in_stream"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text_in_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>Optical Character Recognition (OCR) detects text in an image and
extracts the recognized characters into a machine-usable character
stream.
Upon success, the OCR results will be returned.
Upon failure, the error code together with an error message will be
returned. The error code can be one of InvalidImageUrl,
InvalidImageFormat, InvalidImageSize, NotSupportedImage,
NotSupportedLanguage, or InternalServerError.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>detect_orientation</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – Whether detect the text orientation in the
image. With detectOrientation=true the OCR service tries to detect the
image orientation and correct it before further processing (e.g. if
it’s upside-down).</p></li>
<li><p><strong>image</strong> (<em>Generator</em>) – An image stream.</p></li>
<li><p><strong>language</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a><em> or
</em><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.OcrLanguages" title="azure.cognitiveservices.vision.computervision.models.OcrLanguages"><em>OcrLanguages</em></a>) – The BCP-47 language code of the text to be detected
in the image. The default value is ‘unk’. Possible values include:
‘unk’, ‘zh-Hans’, ‘zh-Hant’, ‘cs’, ‘da’, ‘nl’, ‘en’, ‘fi’, ‘fr’, ‘de’,
‘el’, ‘hu’, ‘it’, ‘ja’, ‘ko’, ‘nb’, ‘pl’, ‘pt’, ‘ru’, ‘es’, ‘sv’,
‘tr’, ‘ar’, ‘ro’, ‘sr-Cyrl’, ‘sr-Latn’, ‘sk’</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>Bytes</em><em>, </em><em>response=None</em><em>]</em>) – When specified, will be called with each chunk of
data that is streamed. The callback should take two arguments, the
bytes of the current chunk of data and the response object. If the
data is uploading, response will be None.</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>OcrResult or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.OcrResult" title="azure.cognitiveservices.vision.computervision.models.OcrResult">OcrResult</a> or
ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_text">
<code class="sig-name descname">recognize_text</code><span class="sig-paren">(</span><em class="sig-param">url</em>, <em class="sig-param">mode</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.recognize_text"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_text" title="Permalink to this definition">¶</a></dt>
<dd><p>Recognize Text operation. When you use the Recognize Text interface,
the response contains a field called ‘Operation-Location’. The
‘Operation-Location’ field contains the URL that you must use for your
Get Recognize Text Operation Result operation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a><em> or
</em><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.TextRecognitionMode" title="azure.cognitiveservices.vision.computervision.models.TextRecognitionMode"><em>TextRecognitionMode</em></a>) – Type of text to recognize. Possible values include:
‘Handwritten’, ‘Printed’</p></li>
<li><p><strong>url</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – Publicly reachable URL of an image.</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.5/library/constants.html#None" title="(in Python v3.5)">None</a> or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_text_in_stream">
<code class="sig-name descname">recognize_text_in_stream</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">mode</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.recognize_text_in_stream"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_text_in_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>Recognize Text operation. When you use the Recognize Text interface,
the response contains a field called ‘Operation-Location’. The
‘Operation-Location’ field contains the URL that you must use for your
Get Recognize Text Operation Result operation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>Generator</em>) – An image stream.</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a><em> or
</em><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.TextRecognitionMode" title="azure.cognitiveservices.vision.computervision.models.TextRecognitionMode"><em>TextRecognitionMode</em></a>) – Type of text to recognize. Possible values include:
‘Handwritten’, ‘Printed’</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>Bytes</em><em>, </em><em>response=None</em><em>]</em>) – When specified, will be called with each chunk of
data that is streamed. The callback should take two arguments, the
bytes of the current chunk of data and the response object. If the
data is uploading, response will be None.</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.5/library/constants.html#None" title="(in Python v3.5)">None</a> or ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image">
<code class="sig-name descname">tag_image</code><span class="sig-paren">(</span><em class="sig-param">url</em>, <em class="sig-param">language='en'</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.tag_image"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation generates a list of words, or tags, that are relevant to
the content of the supplied image. The Computer Vision API can return
tags based on objects, living beings, scenery or actions found in
images. Unlike categories, tags are not organized according to a
hierarchical classification system, but correspond to image content.
Tags may contain hints to avoid ambiguity or provide context, for
example the tag “cello” may be accompanied by the hint “musical
instrument”. All tags are in English.
Two input methods are supported – (1) Uploading an image or (2)
specifying an image URL.
A successful response will be returned in JSON. If the request failed,
the response will contain an error code and a message to help
understand what went wrong.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>url</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – Publicly reachable URL of an image.</p></li>
<li><p><strong>language</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – The desired language for output generation. If this
parameter is not specified, the default value is
&amp;quot;en&amp;quot;.Supported languages:en - English, Default. es -
Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.
Possible values include: ‘en’, ‘es’, ‘ja’, ‘pt’, ‘zh’</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>TagResult or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.TagResult" title="azure.cognitiveservices.vision.computervision.models.TagResult">TagResult</a> or
ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image_in_stream">
<code class="sig-name descname">tag_image_in_stream</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">language='en'</em>, <em class="sig-param">custom_headers=None</em>, <em class="sig-param">raw=False</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">**operation_config</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.html#ComputerVisionClientOperationsMixin.tag_image_in_stream"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image_in_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation generates a list of words, or tags, that are relevant to
the content of the supplied image. The Computer Vision API can return
tags based on objects, living beings, scenery or actions found in
images. Unlike categories, tags are not organized according to a
hierarchical classification system, but correspond to image content.
Tags may contain hints to avoid ambiguity or provide context, for
example the tag “cello” may be accompanied by the hint “musical
instrument”. All tags are in English.
Two input methods are supported – (1) Uploading an image or (2)
specifying an image URL.
A successful response will be returned in JSON. If the request failed,
the response will contain an error code and a message to help
understand what went wrong.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>Generator</em>) – An image stream.</p></li>
<li><p><strong>language</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#str" title="(in Python v3.5)"><em>str</em></a>) – The desired language for output generation. If this
parameter is not specified, the default value is
&amp;quot;en&amp;quot;.Supported languages:en - English, Default. es -
Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.
Possible values include: ‘en’, ‘es’, ‘ja’, ‘pt’, ‘zh’</p></li>
<li><p><strong>custom_headers</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/stdtypes.html#dict" title="(in Python v3.5)"><em>dict</em></a>) – headers that will be added to the request</p></li>
<li><p><strong>raw</strong> (<a class="reference external" href="https://docs.python.org/3.5/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) – returns the direct response alongside the
deserialized response</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>Bytes</em><em>, </em><em>response=None</em><em>]</em>) – When specified, will be called with each chunk of
data that is streamed. The callback should take two arguments, the
bytes of the current chunk of data and the response object. If the
data is uploading, response will be None.</p></li>
<li><p><strong>operation_config</strong> – <span class="xref std std-ref">Operation configuration
overrides</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>TagResult or ClientRawResponse if raw=true</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.TagResult" title="azure.cognitiveservices.vision.computervision.models.TagResult">TagResult</a> or
ClientRawResponse</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference internal" href="azure.cognitiveservices.vision.computervision.models.html#azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException" title="azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComputerVisionErrorException</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="azure.cognitiveservices.vision.contentmoderator.html" class="btn btn-neutral float-right" title="azure.cognitiveservices.vision.contentmoderator package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="azure.cognitiveservices.vision.computervision.models.html" class="btn btn-neutral float-left" title="azure.cognitiveservices.vision.computervision.models module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Microsoft

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
 
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-62780441-36"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-62780441-36');
</script>


</body>
</html>